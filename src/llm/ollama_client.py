"""
This module provides a client for interacting with the Ollama API.

It initializes the Ollama class, which attempts to establish a connection to the Ollama API endpoint specified in the 
configuration file. If successful, it retrieves a list of available models from the API and logs a message indicating 
that Ollama is available. If the connection fails, it logs a warning message indicating that Ollama is not available.

The module defines the `Ollama` class with the following methods:
- `inference(self, model_id: str, prompt: str) -> str`: Inference function that takes in a model ID and a prompt 
string, and returns a response string.

"""

import ollama
from src.logger import Logger
from src.config import Config

log = Logger()

"""_summary_

Returns:
    _type_: _description_
"""
class Ollama:
    """
    Initializes the Ollama class.

    This method attempts to establish a connection to the Ollama API endpoint specified in the configuration file.
    If successful, it retrieves a list of available models from the API and logs a message indicating that 
    Ollama is available. If the connection fails, it logs a warning message indicating that Ollama is not available.

    Parameters:
        None

    Returns:
        None
    """
    def __init__(self):
        try:
            self.client = ollama.Client(Config().get_ollama_api_endpoint())
            self.models = self.client.list()["models"]
            log.info("Ollama available")
        except ConnectionError as e:
            self.client = None
            print(e)
            log.warning("Ollama not available")
            log.warning("run ollama server to use ollama models otherwise use API models")

    def inference(self, model_id: str, prompt: str) -> str:
        """
        Inference function that takes in a model ID and a prompt string, and returns a response string.

        :param model_id: A string representing the ID of the model to use for inference.
        :param prompt: A string representing the prompt to use for inference.
        :return: A string representing the response generated by the model.
        """
        response = self.client.generate(
            model=model_id,
            prompt=prompt.strip()
        )
        return response['response']
